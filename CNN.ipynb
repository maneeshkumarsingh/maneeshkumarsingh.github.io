{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier =Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANEESH\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 1 convolution\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape=(64,64,3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Pooling, resud the size of feacher map and time complexicity\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 flatten\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANEESH\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\MANEESH\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim=128, activation='relu'))\n",
    "classifier.add(Dense(output_dim=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANEESH\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\MANEESH\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., epochs=25, validation_data=<keras_pre..., steps_per_epoch=250, validation_steps=200)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 440s 2s/step - loss: 0.7030 - acc: 0.6098 - val_loss: 0.7540 - val_acc: 0.5907\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 247s 989ms/step - loss: 0.5938 - acc: 0.6832 - val_loss: 0.5694 - val_acc: 0.7099\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 203s 811ms/step - loss: 0.5606 - acc: 0.7144 - val_loss: 0.5733 - val_acc: 0.7190\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 114s 456ms/step - loss: 0.5459 - acc: 0.7181 - val_loss: 0.5930 - val_acc: 0.6999\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 131s 523ms/step - loss: 0.5291 - acc: 0.7339 - val_loss: 0.5456 - val_acc: 0.7270\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 132s 528ms/step - loss: 0.5206 - acc: 0.7444 - val_loss: 0.5327 - val_acc: 0.7476\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 132s 530ms/step - loss: 0.5125 - acc: 0.7462 - val_loss: 0.5593 - val_acc: 0.7185\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 136s 545ms/step - loss: 0.4944 - acc: 0.7577 - val_loss: 0.6266 - val_acc: 0.6831\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 141s 563ms/step - loss: 0.4868 - acc: 0.7620 - val_loss: 0.6064 - val_acc: 0.7166\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 147s 587ms/step - loss: 0.4725 - acc: 0.7720 - val_loss: 0.5653 - val_acc: 0.7352\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 132s 529ms/step - loss: 0.4596 - acc: 0.7835 - val_loss: 0.4990 - val_acc: 0.7686\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 141s 565ms/step - loss: 0.4473 - acc: 0.7895 - val_loss: 0.5751 - val_acc: 0.7375\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 486s 2s/step - loss: 0.4338 - acc: 0.7980 - val_loss: 0.5159 - val_acc: 0.7702\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 441s 2s/step - loss: 0.4218 - acc: 0.8039 - val_loss: 0.5006 - val_acc: 0.7804\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 173s 690ms/step - loss: 0.4058 - acc: 0.8154 - val_loss: 0.5096 - val_acc: 0.7755\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 106s 426ms/step - loss: 0.4048 - acc: 0.8144 - val_loss: 0.5333 - val_acc: 0.7645\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 112s 448ms/step - loss: 0.3891 - acc: 0.8212 - val_loss: 0.5393 - val_acc: 0.7694\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 100s 398ms/step - loss: 0.3782 - acc: 0.8311 - val_loss: 0.5378 - val_acc: 0.7770\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 99s 395ms/step - loss: 0.3726 - acc: 0.8337 - val_loss: 0.5829 - val_acc: 0.7558\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 100s 401ms/step - loss: 0.3553 - acc: 0.8415 - val_loss: 0.6353 - val_acc: 0.7360\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 101s 403ms/step - loss: 0.3408 - acc: 0.8505 - val_loss: 0.6397 - val_acc: 0.7486\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 286s 1s/step - loss: 0.3319 - acc: 0.8569 - val_loss: 0.5813 - val_acc: 0.7599\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 413s 2s/step - loss: 0.3267 - acc: 0.8574 - val_loss: 0.5924 - val_acc: 0.7604\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 182s 729ms/step - loss: 0.3065 - acc: 0.8701 - val_loss: 0.5974 - val_acc: 0.7543\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 96s 385ms/step - loss: 0.3043 - acc: 0.8710 - val_loss: 0.5723 - val_acc: 0.7686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e1429f8358>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('C:/Users/MANEESH/Desktop/dataset/training_set',target_size=(64, 64),batch_size=32,class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('C:/Users/MANEESH/Desktop/dataset/test_set',target_size=(64, 64),batch_size=32,class_mode='binary')\n",
    "\n",
    "classifier.fit_generator(training_set,samples_per_epoch=8000,epochs=25,validation_data=test_set,nb_val_samples=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
